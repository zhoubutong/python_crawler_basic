#使用结巴分词，词性标注是很简单的事情，小问题在于：去停词后，怎么保留分词和词性标注的正确组合
import jieba
import jieba.posseg as pseg
import time
import MySQLdb
import pandas as pd
from pandas import Series,DataFrame

#定义function,词性标注后用DataFrame进行数据规整，去除停词及其标注。pandas不熟悉，用的很傻
def labels(text):
    default_mode = pseg.cut(text)
    #c=[' '.join('%s %s'%(word,flag)) for word,flag in default_mode]
    words=[]
    flags=[]
    for word,flag in default_mode:
        words.append(word)
        flags.append(flag)    
    data={'seg':words,'label':flags} 
    frame=DataFrame(data,columns=['seg','label'])
    for i in range(len(frame)):
        if frame.seg[i] in stopw:
            print "true"
            frame=frame.drop(i)
    seg=list(frame.seg)
    labels=list(frame.label)
    tag=[]
    for i in range(len(seg)):
        tag.append('/'.join([seg[i],labels[i]]))
    tags=','.join(tag)        
    return tags

#仅仅分词，去去停词
def segment(text):
    default_mode = jieba.cut(text)
    notags=','.join(set(default_mode)-set(stopw))
    return notags

#数据存于数据库中，读取，修改，提交
conn=MySQLdb.connect(host='localhost',user='root',passwd='zhou',port=3306,db='dragonpass',charset='utf8')
cur=conn.cursor()
cur.execute('set foreign_key_checks=0')   
stopw = [line.strip().decode('utf-8') for line in open('C:\\Users\\lenovo\\Documents\\stopword.txt').readlines()]

     
for i in range(1,49638):
    selectsql="select comment_content from comments_all where comment_id='%s'"%(i)
    cur.execute(selectsql) 
    result = cur.fetchall()
    text=result[0][0]
    notags=segment(text)     
    insertsql="update comments_all set seg_content='%s' where comment_id='%s'"%(notags,i)    
    cur.execute(insertsql)
    tags=labels(text)  
    print tags
    insertsql2="update comments_all set seg_content_tag='%s' where comment_id='%s'"%(tags,i)    
    cur.execute(insertsql2)
    print "第"+str(i)+"条分词完毕"
    
conn.commit()
cur.execute('set foreign_key_checks=1') 
cur.close()
conn.close()    
